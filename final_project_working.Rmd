---
title: "Your Experience or looks – What matters most in LinkedIn?"
author: "Bryan Morgan, Alan Tan and Debasish Mukhopadhyay"
date: "4/3/2019"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**************
* Suggested Format: 
- Statement of the research question; why this is interesting to
  someone who is predisposed to be interested; what other people know
  about this; what (if any) obsrevational work has to say about this question
- Clear statement of the experiment
  - Research Design (using =ROXO= grammar)
  - Randomization engineering 
  - Experimental materials (e.g. treatment materials)
  - Measurement of variables
  - Modeling choices
- Clear statement of results
  - In text description of your results
  - Figures and tables that support your in text description
  - Clean, clear, well articulated relationships between your theory,
    your hypotheses, the numbers that your models produce, and the
    figures you present. 
*********************
## Background
LinkedIn has been the ubiquitous platform for the professional networking and job search. With 610 million users, 146 million in USA alone, makes it single most important profesional networking place in the world. LinkedIn is extremely popular globally. It is present in more than 200 countries. 40% of it's users visit LinkedIn site daily. One may ask, why do these people come to LinkedIn. It is now a survival tool for professionals in a highly connected World. Here different professionals learn about what is happenning in their industry and profession and learn from others. 80% of LinkedIn members consider professional networking is key to their career success. https://blog.linkedin.com/2017/april/13/introducing-a-smarter-way-to-message-and-build-meaningful-relationships-on-linkedin It is 

A typical user of LinkedIn creates her digital resume, called "profile" and create a graph of connections with friends, coleagues and acquantances. An user with 1000 connections will potentially have more than 11 million connection in a job market. WhileUsers have an option to include a photograph in their profile. LinkedIn research shows that profiles with a headshot gets 21 times more profile views compared to profiles without pictures https://blog.linkedin.com/2016/08/03/5-steps-to-improve-your-linkedin-profile-in-minutes-. Same research also suggests that having a profile picture increases your chance to receive a message by 36 times. 

An accepted rule in LinkedIn profile is to have a very professional picture. A simple web search shows more than 120 websites suggests various rules for LinkedIn profile images. They all claim – Image quality matters. However no scientific research has been done so far to prove that to be the case. As a part of the W241 course, we wanted to run a scientific experiment to prove if it really matters to have professional pictures in your profile.

## Research Question
In a connected world of data and algorithms, does your look matter in your professional social network and employment?

We are setting up an experiment where want to test this. In our experiment, the null hypothesis is that the quality of profile picture does not matter. 

## Why is this research is important
We know that a picture worth a thousands words. In your picture, you show Your physical, psychological, economical, environmental conditions through your presentation, gesture, dress, background,expressions etc. A person, or ML algorithms can guess your race, religion, location [GPS coordinates in metadata], age, sexual orientation etc. 

## Research Design

### Null Hypothesis

### Treatment and control

### Subjects 

### Randamization Strategy
3 members of the team each reached out to 10-12 friends and recruited them as our volunteers (32 in total).  We each randomly selected half of our volunteers as control using random functions in Excel and R, the other half are assigned as treatment. 

We asked our volunteers each monitor and report their profile views to us.  This is to avoid unintended affect to number of views (our view of their profile would have artificially increased their profile views.)

The half of volunteers assigned to treatment are asked to change their profile picture to a worse version according to previous description on the 14th day of our experiment. (16 people are in treatment and all changed their profile pictures on that day.) 

Blocking:
The reason each one of us randomly selected half of our volunteers as treatment is we believe blocking is needed.  The 3 team members are from three different geographical localtions (the Bay area, Seattle, and Toronto), and we have slightly different connections in LinkedIn.  We anticipate the effect of profile pictures could be different based on region, or job categories, or LinkedIn active level.  By blocking by "volunteer contact", we hope to limit the impact of differences between groups of people (for example some team member's contacts have in average much higher profile views than others)

### Measurement Process
We measuree "number of profile views" as our outcome. 

A view is when a LinkedIn user clicks on a the profile brief to open the profile details. 
LinkedIn people search result shows this profile briefs, with profile picture in a list format.  A user will click on this profile brief is they are interested in a particular profile, and view more detailed information for the person.  Because the profile picture is shown with name, headline, and title shown, so we anticipate profile picture is an important part of the information affecting a viewer's decision to click on the brief or not. 

Sources of profile views might include, but not limited to: Recruiters looking for candidate, or industry insider looking for contact, employer, or mentor, it could be just a google user searching for someone with similar names or background.

A complication is search engines might serve direct link to a profile detail page by passing the profile brief list, where profile picture is part of the decision to view detail or not, which can be a concern for real user profiles, especially those influencers on LinkedIn. 

To address this concern, we take 2 weeks of "before" and 2 weeks "after" profile pic changes, then compare the differences of before and after.  Because the search engie originated views are not affected by the profile pictures (search engines do not show profile pictures), so the differences between the two periods would not affected by such views.  
So, we took a Difference in Different approach, to remove the influence of the search engine originated views. 

DnD = Before_views – After_views



### ROXO 
Considering the possibilities of substantially different baselines we took a difference in difference approach
We felt this would help mitigate potential noise and help us isolate any potential treatment effect
We took 10+ individuals each, and randomly assigned them to control or treatment
From there we observed 2 weeks of their LinkedIn data, prior to the experiment
We then administered treatment, confirmed compliance and then observed again after 2 weeks

### Pilot and learning

## Analysis 




```{r}
library(stargazer)
library(multiwayvcov)  
library(sandwich)
library(ri)
library(dplyr)
library(pwr)
library(psych)
```
```{r pressure, echo=FALSE, fig.cap="A caption", out.width = '100%'}
knitr::include_graphics("finalproject/slide2.png")
```
```{r table}
#knitr::kable(mtcars[1:5,, 1:5], caption = "A table caption")
knitr::include_graphics(rep("finalproject/slide2.png", 3))
```
Set things up

```{r}
main_dataFrame <- data.frame(
  "source" = c("1","1","1","1","1","1","1","1","1","1","2","2","2","2","2","2","2","2","2","2","3","3","3","3","3","3","3","3","3","3","3","3"),
  "week1" = c(12,10,3,2,6,8,6,1,1,7,8,NaN,22,11,1,13,3,59,7,1,6,4,1,12,3,31,20,6,3,15,3,2),
  "week2" = c(19,6,3,5,7,7,2,1,2,10,10,NaN,13,6,0,4,3,17,6,0,2,4,1,12,3,31,20,6,3,15,3,2),
  "week3" = c(12,2,6,4,7,9,5,1,10,7,6,NaN,24,9,1,6,14,14,2,0,1,7,2,15,2,27,16,5,4,9,2,2),
  "week4" = c(17,2,13,6,9,32,5,1,3,7,7,NaN,13,6,4,6,7,9,3,0,1,7,2,8,2,4,10,4,3,9,1,2),
  "treatment" = c(1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,0,0,0,0,1,1,0,0,1,0,0,1,1,0,1,0),
  "Female" = c(0,1,1,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,1),
  "Age" = c("20","30","20","40","30","40","30","30","20","30","20","50","40","40","30","40","20","40","50","30","40","60","50","40","40","40","40","30","40","50","40","20"),
  "Highest_Ed" = c("Bachelor","High School","Bachelor","Masters","Bachelor","Bachelor","Masters","Bachelor","Bachelor","Bachelor","Masters","Bachelor","Bachelor","Masters","Bachelor","Bachelor","Bachelor","Masters","Masters","Bachelor","Masters","PhD","PhD","Masters","Masters","PhD","Masters","Bachelor","PhD","Masters","Masters","PhD"),
  "West Coast" = c(1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1),
  "Tech Field" = c(1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1)
  #"Actively Looking" = c(0,0,1,0,0,1,0,0,0,0,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,0,1,0,1,1,1,1,1,0,0,0,0)
)

main_dataFrame$DnD <- (main_dataFrame$week3+main_dataFrame$week4) - (main_dataFrame$week1+main_dataFrame$week2)
```

```{r}
main_noNA_df <- na.omit(main_dataFrame)
```


```{r}
ri_y <- main_noNA_df$DnD
ri_Z <- main_noNA_df$treatment
ri_block <- main_noNA_df$source

perms <- genperms(ri_Z, blockvar = ri_block)
probs <- genprobexact(ri_Z, blockvar = ri_block)
ate <- estate(ri_y, ri_Z, prob = probs)

Ys <- genouts(ri_y, ri_Z, ate=0)
distout <- gendist(Ys, perms, prob = probs)
dispdist(distout, ate)
```

```{r}
ate
```



```{r}
main_lm_nieve <- lm(DnD ~ treatment + source, data=main_noNA_df)
main_lm_nieve_summary <- summary(main_lm_nieve)
main_lm_nieve_summary
```

```{r}
stargazer(coeftest(main_lm_nieve,vcov.=vcovHC(main_lm_nieve,type="HC1")), type = "text")
```


```{r}
main_lm_covariate <- lm(DnD ~ treatment + Female + Highest_Ed + Age, data=main_noNA_df)
main_lm_covariate_summary <- summary(main_lm_covariate)
main_lm_covariate_summary
```

```{r}
stargazer(coeftest(main_lm_covariate,vcov.=vcovHC(main_lm_covariate,type="HC1")), type = "text")
```

```{r}
control_mean <- mean(main_noNA_df$DnD[main_noNA_df$treatment == 0])
treatment_mean <- mean(main_noNA_df$DnD[main_noNA_df$treatment == 1])
sample_std <- sd(main_noNA_df$DnD)
max_dnd <- max(main_noNA_df$DnD)
min_dnd <- min(main_noNA_df$DnD)
describe(main_noNA_df$DnD)

#Basic info calculations
sample_std
control_mean
treatment_mean
max_dnd
min_dnd
anova(main_lm_covariate)
```

```{r}
#Calculate Power
pwr.f2.test(u =9, v =21, f2 =(0.1273/(1-0.1273)) , sig.level = 0.05)
```

## Generalizability
Considering the possibilities of substantially different baselines we took a difference in difference approach
We felt this would help mitigate potential noise and help us isolate any potential treatment effect
We took 10+ individuals each, and randomly assigned them to control or treatment
From there we observed 2 weeks of their LinkedIn data, prior to the experiment
We then administered treatment, confirmed compliance and then observed again after 2 weeks

However, our sample size is very small compare to how many co-variates LinkedIn collect people's information, and ways to categorize its users. 
We need much more volunteers to control for factors like 
-level of activeness on LinkedIn introduces lots of variance
-gendere/age
-career status/seniority
-nature of work
-industry

We also need a standarization approach to "make a picture bad".  While there are many qualitative discussions of what is a good .vs. bad profile picture, an objective standard is needed to be able to generalize our findings.  



## Conclusion
Use a paid campaign in LinkedIn to recruite random volunteers with random backgrounds to avoid selection bias

Run the experiment for multiple weeks so that each volunteer can have multiple treatments 

Use automation to create treatment "dosage"

Collect more covariate  information to better understand variability around professionals such as bloggers, writers who likely to have high variability in profile views



